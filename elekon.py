# -*- coding: utf-8 -*-
"""elekon

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1956Ukem-IRNKwr4mdPu3javRk4JuFi0l
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read image.
img = cv2.imread('/content/drive/MyDrive/IMG_0038.JPG', cv2.IMREAD_COLOR)

# Convert to grayscale.
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

plt.imshow(img[1200:2500,1900:3200])

plt.imshow(gray[1200:2500,1900:3200],cmap='gray')

# Blur the image for better edge detection
img_blur = cv2.GaussianBlur(gray, (3,3), 0)
plt.imshow(img_blur[1200:2500,1900:3200],cmap='gray')

import cv2

canny = cv2.Canny(img_blur,0,100)
plt.imshow(canny[1200:2500,1900:3200],cmap = 'gray')

depth=cv2.CV_16S # -1
kernel_size = 5
xorder=1
yorder=0
laplacian = cv2.Laplacian(img_blur,ddepth=depth,ksize=kernel_size)
#sobel=cv2.Sobel(img_blur,depth,xorder,yorder,kernel_size)
plt.imshow(sobel[1200:2500,1900:3200],cmap='gray')

depth=cv2.CV_16S # -1
kernel_size = 5
xorder=1
yorder=0
sobel=cv2.Sobel(img_blur,depth,xorder,yorder,kernel_size)
plt.imshow(sobel[1200:2500,1900:3200],cmap='gray')

depth=cv2.CV_16S # -1
kernel_size = 3
prewitt=cv2.filter2D(img_blur, depth, kernel_size)
plt.imshow(prewitt[1200:2500,1900:3200],cmap='gray')

depth=cv2.CV_16S # -1
xorder=0
yorder=1
scharr=cv2.Scharr(img, depth, xorder, yorder)
plt.imshow(scharr[1200:2500,1900:3200],cmap='gray')

# img 3 channels 0, 255
# gray 1 channel min,max=5,255
# img_blur 8, 255
# canny 0,255 +
# laplacian -4236, 3008
# sobel -645,592
# prewitt 24, 765
# scharr -3234, 3255

fig = plt.figure(figsize=(5,5))
ax=fig.subplots(1,6)
i=0
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[0].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')
i=1
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[1].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')
i=2
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[2].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')
i=3
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[3].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')
i=4
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[4].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')
i=5
x,y,r=circles[i][0],circles[i][1],circles[i][2]
ax[5].imshow(gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r],cmap = 'gray')

fig.subplots_adjust(right = 4)

from torch.utils.data import Dataset
import torch
import cv2
import matplotlib.pyplot as plt
import os

path='/content/drive/MyDrive/results/'

class CustomDataset(Dataset):

  def __init__(self,path):
    self.samples=[]
    for name_folder in ['1','0_0']:
      if name_folder=='1':
        self.samples.extend([(path+name_folder+'/'+name_file,1) for name_file in  os.listdir(path+name_folder)])
      else:
        self.samples.extend([(path+name_folder+'/'+name_file,0) for name_file in  os.listdir(path+name_folder)])

  def __len__(self):
    return len(self.samples)

  def __getitem__(self,idx):
    return cv2.resize(cv2.imread(self.samples[idx][0],cv2.IMREAD_GRAYSCALE),(150,150)),self.samples[idx][1]

import torch.nn as nn

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2)

        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2)

        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.relu3 = nn.ReLU()
        self.pool3 = nn.MaxPool2d(kernel_size=2)

        self.fc1 = nn.Linear(in_features=64*18*18, out_features=512)
        self.relu4 = nn.ReLU()
        #self.dropout = nn.Dropout(p=0.5)

        self.fc2 = nn.Linear(in_features=512, out_features=1)

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)

        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)

        x = self.conv3(x)
        x = self.relu3(x)
        x = self.pool3(x)

        x = x.view(-1, 64*18*18)
        x = self.fc1(x)
        x = self.relu4(x)
        #x = self.dropout(x)

        x = torch.sigmoid(self.fc2(x))

        return x

import h5py
import torch
import torch.optim as optim
#import torchvision.transforms as transforms
from torch.autograd import Variable
import matplotlib.pyplot as plt
#import torchvision
import numpy as np
from torch.utils.tensorboard import SummaryWriter
from sklearn.metrics import f1_score, precision_score, recall_score

import random
import time
import pickle

#from model import *
#from dataset_regression import *

torch.manual_seed(0)
random.seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print('device_name, ', device)

# #path_to_h5 = 'C:/Users/Admin/PycharmProjects/Location/dataset_snr_2_15_sn_0.4_1.0_rot.h5'
# path_to_h5 = '/home/ilias/pycharm_project_42/dataset_snr_2_15_sn_0.4_1.0_rot.h5'
data = CustomDataset(path)
#train_set = CustomDataset(path_to_file='C:/Users/Admin/PycharmProjects/Location/dataset_snr_check_2.h5', shuffle=True)
#train_set = CustomDataset(path_to_file=path_to_h5, shuffle=True)
#val_set = CustomDataset(path_to_file=path_to_h5, shuffle=True)
#val_set = CustomDataset(path_to_file='C:/Users/Admin/PycharmProjects/Location/dataset_snr_check_2.h5', shuffle=True)
train_set, val_set = torch.utils.data.random_split(data, [int(0.8 * len(data)), len(data) - int(0.8 * len(data))])

batch_size = 5
train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)
test_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size)

model = CNN()
model = model.to(device)
print('model on cuda', next(model.parameters()).is_cuda)
criterion = nn.L1Loss()
# optimizer = optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)
optimizer = optim.Adam(model.parameters(), lr=1e-6)

print('model train...')

loss_train_epoch = []
loss_test_epoch = []
predicted_labels = {}
results_labels = {}

#train_log = SummaryWriter('/runs/train/')
#test_log = SummaryWriter('runs/test/')

for epoch in range(100):

    model.train()
    start = time.time()
    train_snr_mean = []
    batch_loss = []
    for i, data in enumerate(train_loader):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        optimizer.zero_grad()
        outputs = model(inputs.float()[:,np.newaxis,:,:])
        #outputs=torch.Tensor([1 if i>0.5  else 0 for i in outputs]).to(device)
        labels = labels.float()
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        batch_loss.append(loss.item())
        train_snr_mean.append(np.mean([l.item() for l in labels]))
        if i % 50 == 0:
            print('epoch', epoch, ',', 'batch', i, ',', 'train loss', loss.item())

    loss_train_epoch.append(sum(batch_loss) / len(batch_loss))
    #train_log.add_scalar('loss', sum(batch_loss) / len(batch_loss), epoch)
    print('epoch', epoch, ',', 'loss', sum(batch_loss) / len(batch_loss))
    print('train_snr_mean', sum(train_snr_mean) / len(train_snr_mean))
    print('time', time.time()-start)

    model.eval()
    batch_loss = []
    predicted_outputs_test = []
    labels_test = []
    val_snr_mean = []
    for i, data in enumerate(test_loader):
        inputs, labels = data
        inputs = inputs.to(device)
        labels = labels.to(device)
        outputs = model(inputs.float()[:,np.newaxis,:,:])
        #outputs=torch.Tensor([1 if i>0.5  else 0 for i in outputs]).to(device)
        labels = labels.float()
        loss = criterion(outputs, labels)
        batch_loss.append(loss.item())
        predicted_outputs_test.extend([i for i in outputs.detach().cpu().numpy()])
        labels_test.extend([i for i in labels.detach().cpu().numpy()])
        val_snr_mean.append(np.mean([l.item() for l in labels]))

    predicted_labels.update({epoch: predicted_outputs_test})
    results_labels.update({epoch: labels_test})


    loss_test_epoch.append(sum(batch_loss) / len(batch_loss))
    #test_log.add_scalar('loss', sum(batch_loss) / len(batch_loss), epoch)
    print('test loss', sum(batch_loss) / len(batch_loss))
    print('val_snr_mean', sum(val_snr_mean) / len(val_snr_mean))

    # if epoch == 0:
    #     torch.save(model.state_dict(), 'Zarubezneft_model_update_snr_2_15_sn_0.4_1.0_rot.pth')
    #     print('new best model found in epoch', epoch)
    # elif loss_test_epoch[epoch - 1] > loss_test_epoch[epoch]:
    #     torch.save(model.state_dict(), 'Zarubezneft_model_update_snr_2_15_sn_0.4_1.0_rot.pth')
    #     print('new best model found in epoch', epoch)
    # if epoch >= 15 and all([loss_test_epoch[epoch] >= loss_test_epoch[j] for j in range(epoch-6, epoch)]):
    #     break

#train_log.flush()
#test_log.flush()
#train_log.close()
#test_log.close()

# with open('model_update_test_predicted_ZarubezNeft_snr_2_15_sn_0.4_1.0_rot.pkl', 'wb') as f:
#     pickle.dump(predicted_labels, f)

# with open('model_update_test_labels_ZarubezNeft_snr_2_15_sn_0.4_1.0_rot.pkl', 'wb') as f:
#     pickle.dump(results_labels, f)

# np.save('model_update_loss_train_ZarubezNeft_snr_2_15_sn_0.4_1.0_rot.npy', np.array(loss_train_epoch))
# np.save('model_update_loss_test_ZarubezNeft_snr_2_15_sn_0.4_1.0_rot.npy', np.array(loss_test_epoch))

# torch.save(model.state_dict(), 'model_01_11.pth')

plt.plot(loss_test_epoch,marker='*',color='k')

# INFERENCE DATA CREATE
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# Load the image
names_images=['IMG_0036.JPG']

i=0
for name_image in names_images:
  img = cv2.imread('/content/drive/MyDrive/elecon/'+name_image, cv2.IMREAD_COLOR) # 30, 9

  # Convert to grayscale.
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  # Apply Gaussian blur to reduce noise
  img_blur=cv2.medianBlur(img,5)
  canny = cv2.Canny(img_blur,0,100)
  img_blur=img_blur[1200:2500,1900:3200]
  canny=canny[1200:2500,1900:3200]

  # Detect circles using HoughCircles function
  circles = cv2.HoughCircles(canny, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=23, param2=23, minRadius=50, maxRadius=80)

  # Draw detected circles on the original image
  if circles is not None:
      circles = np.round(circles[0, :]).astype("int")
      for (x, y, r) in circles:
          cv2.imwrite('/content/drive/MyDrive/inference/'+str(i)+'.png',gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r])
          i=i+1

# INFERENCE
import os

path_to_inference_data='/content/drive/MyDrive/inference/'
#inference_data = CustomDataset(path)
#batch_size = 2
#inference_loader = torch.utils.data.DataLoader(inference_data, batch_size=batch_size)

model.eval()
labels_test=[]
predicted_outputs_test = []
#for i, data in enumerate(test_loader):
for name_image in os.listdir(path_to_inference_data):
    image=cv2.resize(cv2.imread(path_to_inference_data+name_image,cv2.IMREAD_GRAYSCALE),(150,150))
    output=model(torch.from_numpy(image).to(device).float()[np.newaxis,:,:])
    print(name_image, round(output.item()))
    #print(model(torch.from_numpy(image).to(device).float()[np.newaxis,:,:]))
    #inputs, labels = data
    #inputs = inputs.to(device)
    #labels = labels.to(device)
    #outputs = model(inputs.float()[:,np.newaxis,:,:])[:, 0]
    #predicted_outputs_test.extend([i for i in outputs.detach().cpu().numpy()])

fig = plt.figure(figsize=(5,5))
ax=fig.subplots(1,6)

image=cv2.resize(cv2.imread(path_to_inference_data+'0.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[0].imshow(image,cmap = 'gray')
ax[0].set_title('predicted 1, 0.png')

image=cv2.resize(cv2.imread(path_to_inference_data+'1.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[1].imshow(image,cmap = 'gray')
ax[1].set_title('predicted 0, 1.png')

image=cv2.resize(cv2.imread(path_to_inference_data+'10.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[2].imshow(image,cmap = 'gray')
ax[2].set_title('predicted 1, 10.png')

image=cv2.resize(cv2.imread(path_to_inference_data+'26.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[3].imshow(image,cmap = 'gray')
ax[3].set_title('predicted 1, 26.png')

image=cv2.resize(cv2.imread(path_to_inference_data+'29.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[4].imshow(image,cmap = 'gray')
ax[4].set_title('predicted 0, 29.png')

image=cv2.resize(cv2.imread(path_to_inference_data+'31.png',cv2.IMREAD_GRAYSCALE),(150,150))
ax[5].imshow(image,cmap = 'gray')
ax[5].set_title('predicted 0, 31.png')

fig.subplots_adjust(right = 4)

#plt.imshow(img_blur,cmap = 'gray') #[1200:2500,1900:3200]
ticks= [i for i in range(0,img_blur.shape[1],40)]
labels= [i for i in range(0,img_blur.shape[1],40)]
plt.xticks(ticks,labels,rotation=90,fontsize=8)
ticks= [i for i in range(0,img_blur.shape[0],40)]
labels= [i for i in range(0,img_blur.shape[0],40)]
plt.yticks(ticks,labels,fontsize=8)
plt.imshow(img_blur)

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# Load the image
names_images=['IMG_0037.JPG','IMG_0038.JPG','IMG_0039.JPG']

i=0
for name_image in names_images:
  img = cv2.imread('/content/drive/MyDrive/elecon/'+name_image, cv2.IMREAD_COLOR) # 30, 9

  # Convert to grayscale.
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  # Apply Gaussian blur to reduce noise
  img_blur=cv2.medianBlur(img,5)
  canny = cv2.Canny(img_blur,0,100)
  img_blur=img_blur[1200:2500,1900:3200]
  canny=canny[1200:2500,1900:3200]

  # Detect circles using HoughCircles function
  circles = cv2.HoughCircles(canny, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=23, param2=23, minRadius=50, maxRadius=80)

  # Draw detected circles on the original image
  if circles is not None:
      circles = np.round(circles[0, :]).astype("int")
      for (x, y, r) in circles:
          cv2.imwrite('/content/drive/MyDrive/results/'+str(i)+'.png',gray[1200:2500,1900:3200][y-r:y+r,x-r:x+r])
          i=i+1

# AUGMENTATION FOR 0 CLASS
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
import os

names_images=os.listdir('/content/drive/MyDrive/results/0/')
coeff_blur=np.arange(1,23,2)

i=0
for name_image in names_images:
  img = cv2.imread('/content/drive/MyDrive/results/0/'+name_image, cv2.IMREAD_COLOR)
  # Convert to grayscale.
  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

  for c_blurr in coeff_blur:
    img_blur=cv2.medianBlur(gray,c_blurr)
    cv2.imwrite('/content/drive/MyDrive/results/0_0/'+str(i)+'.png', img_blur)
    i=i+1

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# Load the image
img = cv2.imread('/content/drive/MyDrive/elecon/IMG_0036.JPG', cv2.IMREAD_COLOR)

# Convert to grayscale.
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply Gaussian blur to reduce noise
#img_blur = cv2.GaussianBlur(gray,(5,5),1)
img_blur=cv2.medianBlur(img,5)
canny = cv2.Canny(img_blur,0,100)
img_blur=img_blur[1200:2500,1900:3200]
canny=canny[1200:2500,1900:3200]

#plt.imshow(img_blur,cmap = 'gray') #[1200:2500,1900:3200]
# ticks= [i for i in range(0,img_blur.shape[1],20)]
# labels= [i for i in range(0,img_blur.shape[1],20)]
# plt.xticks(ticks,labels,rotation=-90,fontsize=8)
# ticks= [i for i in range(0,img_blur.shape[0],20)]
# labels= [i for i in range(0,img_blur.shape[0],20)]
# plt.yticks(ticks,labels,fontsize=8)
#img_blur=cv2.line(img_blur, (200,700), (300,700), (0, 255, 0), 9)
#cv2_imshow(img_blur)

# Detect circles using HoughCircles function
circles = cv2.HoughCircles(canny, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=23, param2=23, minRadius=50, maxRadius=80)
#circles = cv2.HoughCircles(img_blur, cv2.HOUGH_GRADIENT, dp=1, minDist=100, param1=3, param2=3, minRadius=50, maxRadius=80)

# Draw detected circles on the original image
if circles is not None:
    circles = np.round(circles[0, :]).astype("int")
    for (x, y, r) in circles:
        cv2.circle(img[1200:2500,1900:3200], (x, y), r, (0,255,0), 2)

# Display the final image with detected circles
#cv2.imshow('Detected Circles', img_blur[1200:1960,1900:2500])
cv2_imshow(img[1200:2500,1900:3200])
cv2.waitKey(0)
cv2.destroyAllWindows()

from google.colab.patches import cv2_imshow

!curl -o logo.png https://colab.research.google.com/img/colab_favicon_256px.png
import cv2
img = cv2.imread('logo.png', cv2.IMREAD_UNCHANGED)
cv2_imshow(img)